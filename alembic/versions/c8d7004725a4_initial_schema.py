"""initial schema

Revision ID: c8d7004725a4
Revises:
Create Date: 2025-10-06 21:03:46.830574

"""

from collections.abc import Sequence

import pgvector.sqlalchemy
import sqlalchemy as sa
import sqlmodel.sql.sqltypes

from alembic import op

# revision identifiers, used by Alembic.
revision: str = "c8d7004725a4"
down_revision: str | Sequence[str] | None = None
branch_labels: str | Sequence[str] | None = None
depends_on: str | Sequence[str] | None = None


def upgrade() -> None:
    """Upgrade schema."""
    # Create pgvector extension
    op.execute("CREATE EXTENSION IF NOT EXISTS vector;")

    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "books",
        sa.Column("id", sa.Uuid(), nullable=False),
        sa.Column("title", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("author", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("kindle_url", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("total_screenshots", sa.Integer(), nullable=False),
        sa.Column("capture_date", sa.DateTime(), nullable=True),
        sa.Column(
            "ingestion_status", sqlmodel.sql.sqltypes.AutoString(), nullable=False
        ),
        sa.Column("ingestion_error", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.Column("book_metadata", sa.JSON(), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("updated_at", sa.DateTime(), nullable=False),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(op.f("ix_books_author"), "books", ["author"], unique=False)
    op.create_index(
        op.f("ix_books_ingestion_status"), "books", ["ingestion_status"], unique=False
    )
    op.create_index(op.f("ix_books_title"), "books", ["title"], unique=False)
    op.create_table(
        "embedding_configs",
        sa.Column("id", sa.Uuid(), nullable=False),
        sa.Column("model_name", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("model_version", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("dimensions", sa.Integer(), nullable=False),
        sa.Column("is_active", sa.Boolean(), nullable=False),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        op.f("ix_embedding_configs_is_active"),
        "embedding_configs",
        ["is_active"],
        unique=False,
    )
    op.create_index(
        op.f("ix_embedding_configs_model_name"),
        "embedding_configs",
        ["model_name"],
        unique=False,
    )
    op.create_table(
        "chunks",
        sa.Column("id", sa.Uuid(), nullable=False),
        sa.Column("book_id", sa.Uuid(), nullable=False),
        sa.Column("screenshot_ids", sa.ARRAY(sa.UUID()), nullable=False),
        sa.Column("chunk_sequence", sa.Integer(), nullable=False),
        sa.Column("chunk_text", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("chunk_token_count", sa.Integer(), nullable=False),
        sa.Column("embedding_config_id", sa.Uuid(), nullable=False),
        sa.Column(
            "embedding", pgvector.sqlalchemy.vector.VECTOR(dim=1536), nullable=True
        ),
        sa.Column("vision_model", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("vision_prompt_tokens", sa.Integer(), nullable=False),
        sa.Column("vision_completion_tokens", sa.Integer(), nullable=False),
        sa.Column("extraction_timestamp", sa.DateTime(), nullable=False),
        sa.Column("chunk_metadata", sa.JSON(), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.ForeignKeyConstraint(
            ["book_id"],
            ["books.id"],
        ),
        sa.ForeignKeyConstraint(
            ["embedding_config_id"],
            ["embedding_configs.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(op.f("ix_chunks_book_id"), "chunks", ["book_id"], unique=False)
    op.create_table(
        "ingestion_logs",
        sa.Column("id", sa.Uuid(), nullable=False),
        sa.Column("book_id", sa.Uuid(), nullable=False),
        sa.Column("pipeline_stage", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("status", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("error_message", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.Column("execution_time_ms", sa.Integer(), nullable=True),
        sa.Column("log_metadata", sa.JSON(), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.ForeignKeyConstraint(
            ["book_id"],
            ["books.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        op.f("ix_ingestion_logs_book_id"), "ingestion_logs", ["book_id"], unique=False
    )
    op.create_index(
        op.f("ix_ingestion_logs_created_at"),
        "ingestion_logs",
        ["created_at"],
        unique=False,
    )
    op.create_index(
        op.f("ix_ingestion_logs_pipeline_stage"),
        "ingestion_logs",
        ["pipeline_stage"],
        unique=False,
    )
    op.create_index(
        op.f("ix_ingestion_logs_status"), "ingestion_logs", ["status"], unique=False
    )
    op.create_table(
        "screenshots",
        sa.Column("id", sa.Uuid(), nullable=False),
        sa.Column("book_id", sa.Uuid(), nullable=False),
        sa.Column("sequence_number", sa.Integer(), nullable=False),
        sa.Column("file_path", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("screenshot_hash", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.Column("captured_at", sa.DateTime(), nullable=False),
        sa.ForeignKeyConstraint(
            ["book_id"],
            ["books.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint(
            "book_id", "sequence_number", name="uq_screenshot_book_sequence"
        ),
    )
    op.create_index(
        op.f("ix_screenshots_book_id"), "screenshots", ["book_id"], unique=False
    )
    op.create_index(
        op.f("ix_screenshots_screenshot_hash"),
        "screenshots",
        ["screenshot_hash"],
        unique=False,
    )

    # Create IVFFlat index for vector similarity search
    op.execute(
        "CREATE INDEX idx_chunks_embedding_ivfflat ON chunks "
        "USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);"
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # Drop IVFFlat index
    op.execute("DROP INDEX IF EXISTS idx_chunks_embedding_ivfflat;")

    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f("ix_screenshots_screenshot_hash"), table_name="screenshots")
    op.drop_index(op.f("ix_screenshots_book_id"), table_name="screenshots")
    op.drop_table("screenshots")
    op.drop_index(op.f("ix_ingestion_logs_status"), table_name="ingestion_logs")
    op.drop_index(op.f("ix_ingestion_logs_pipeline_stage"), table_name="ingestion_logs")
    op.drop_index(op.f("ix_ingestion_logs_created_at"), table_name="ingestion_logs")
    op.drop_index(op.f("ix_ingestion_logs_book_id"), table_name="ingestion_logs")
    op.drop_table("ingestion_logs")
    op.drop_index(op.f("ix_chunks_book_id"), table_name="chunks")
    op.drop_table("chunks")
    op.drop_index(
        op.f("ix_embedding_configs_model_name"), table_name="embedding_configs"
    )
    op.drop_index(
        op.f("ix_embedding_configs_is_active"), table_name="embedding_configs"
    )
    op.drop_table("embedding_configs")
    op.drop_index(op.f("ix_books_title"), table_name="books")
    op.drop_index(op.f("ix_books_ingestion_status"), table_name="books")
    op.drop_index(op.f("ix_books_author"), table_name="books")
    op.drop_table("books")
    # ### end Alembic commands ###
