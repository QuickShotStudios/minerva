# Story 3.4: Book and Chunk Retrieval Endpoints

## Status
Ready for Review

## Story

**As a** MyPeptidePal.ai developer,
**I want** endpoints to list books and retrieve specific book/chunk details,
**so that** I can browse the knowledge base and provide source attribution.

## Acceptance Criteria

1. Books list endpoint created: GET /api/v1/books with optional query parameters: limit (default 20), offset (default 0), status (filter by ingestion_status)
2. Books list response includes: books array (id, title, author, total_screenshots, total_chunks, capture_date, ingestion_status), total count, has_more boolean
3. Book details endpoint created: GET /api/v1/books/{book_id} returns full book details including metadata
4. Book details response includes: all book fields, chunk count, screenshot count, ingestion logs (recent errors/warnings)
5. Chunk details endpoint created: GET /api/v1/chunks/{chunk_id} returns chunk with context
6. Chunk details response includes: chunk_id, chunk_text, chunk_sequence, chunk_token_count, book object, screenshot_ids, vision_model, context object (previous_chunk text, next_chunk text)
7. Context retrieval: previous/next chunks fetched based on chunk_sequence for same book
8. All endpoints handle not found: 404 response with clear error message if book_id or chunk_id doesn't exist
9. Books endpoint supports pagination: offset/limit correctly slice results, total count accurate
10. OpenAPI docs include all three endpoints with schemas and examples
11. Integration tests validate: list books → retrieve specific book → retrieve chunk from that book (full workflow)

## Tasks / Subtasks

### Task 1: Create Book and Chunk Pydantic schemas (AC: 2, 4, 6)
- [ ] Create `minerva/api/schemas/books.py` for book schemas
  ```python
  from pydantic import BaseModel, Field
  from uuid import UUID
  from datetime import datetime

  class BookListItem(BaseModel):
      id: UUID
      title: str
      author: str | None
      total_screenshots: int | None
      total_chunks: int
      capture_date: datetime
      ingestion_status: str

  class BooksListResponse(BaseModel):
      books: list[BookListItem]
      total_count: int
      has_more: bool

      class Config:
          schema_extra = {
              "example": {
                  "books": [
                      {
                          "id": "123e4567-e89b-12d3-a456-426614174000",
                          "title": "Peptide Therapy Guide",
                          "author": "Dr. John Smith",
                          "total_screenshots": 209,
                          "total_chunks": 185,
                          "capture_date": "2025-10-06T10:30:00Z",
                          "ingestion_status": "completed"
                      }
                  ],
                  "total_count": 5,
                  "has_more": False
              }
          }

  class IngestionLogItem(BaseModel):
      log_level: str
      message: str
      created_at: datetime

  class BookDetail(BaseModel):
      id: UUID
      title: str
      author: str | None
      kindle_url: str
      total_screenshots: int | None
      total_chunks: int
      capture_date: datetime
      ingestion_status: str
      ingestion_error: str | None
      metadata: dict | None
      created_at: datetime
      updated_at: datetime
      recent_logs: list[IngestionLogItem]
  ```
- [ ] Create chunk schemas in same file
  ```python
  class ChunkContext(BaseModel):
      previous_chunk: str | None = Field(None, description="Text from previous chunk")
      next_chunk: str | None = Field(None, description="Text from next chunk")

  class ChunkDetail(BaseModel):
      chunk_id: UUID
      chunk_text: str
      chunk_sequence: int
      chunk_token_count: int
      book: BookListItem  # Reuse BookListItem for consistency
      screenshot_ids: list[UUID]
      vision_model: str
      context: ChunkContext
  ```

### Task 2: Create GET /api/v1/books endpoint (AC: 1, 2, 9)
- [ ] Create `minerva/api/routes/books.py` router
- [ ] Implement list books endpoint with pagination
  ```python
  from fastapi import APIRouter, Depends, Query, HTTPException, status
  from sqlalchemy import select, func
  from sqlalchemy.ext.asyncio import AsyncSession

  from minerva.api.dependencies import get_db
  from minerva.api.schemas.books import BooksListResponse, BookListItem
  from minerva.db.models.book import Book
  from minerva.db.models.chunk import Chunk

  router = APIRouter(prefix="/books", tags=["books"])

  @router.get(
      "",
      response_model=BooksListResponse,
      summary="List books",
      description="Retrieve paginated list of books in knowledge base"
  )
  async def list_books(
      limit: int = Query(20, ge=1, le=100, description="Results per page"),
      offset: int = Query(0, ge=0, description="Page offset"),
      status: str | None = Query(None, description="Filter by ingestion_status"),
      db: AsyncSession = Depends(get_db)
  ) -> BooksListResponse:
      # Build query
      query = select(
          Book.id,
          Book.title,
          Book.author,
          Book.total_screenshots,
          Book.capture_date,
          Book.ingestion_status,
          func.count(Chunk.id).label('total_chunks')
      ).outerjoin(Chunk, Book.id == Chunk.book_id).group_by(Book.id)

      # Apply status filter
      if status:
          query = query.where(Book.ingestion_status == status)

      # Get total count
      count_query = select(func.count()).select_from(Book)
      if status:
          count_query = count_query.where(Book.ingestion_status == status)
      total_count = await db.scalar(count_query)

      # Apply pagination
      query = query.order_by(Book.created_at.desc()).offset(offset).limit(limit)

      # Execute query
      result = await db.execute(query)
      rows = result.all()

      # Build response
      books = [
          BookListItem(
              id=row.id,
              title=row.title,
              author=row.author,
              total_screenshots=row.total_screenshots,
              total_chunks=row.total_chunks,
              capture_date=row.capture_date,
              ingestion_status=row.ingestion_status
          )
          for row in rows
      ]

      return BooksListResponse(
          books=books,
          total_count=total_count or 0,
          has_more=(offset + limit) < (total_count or 0)
      )
  ```

### Task 3: Create GET /api/v1/books/{book_id} endpoint (AC: 3, 4)
- [ ] Implement book details endpoint
  ```python
  @router.get(
      "/{book_id}",
      response_model=BookDetail,
      summary="Get book details",
      description="Retrieve full book details including logs"
  )
  async def get_book(
      book_id: UUID,
      db: AsyncSession = Depends(get_db)
  ) -> BookDetail:
      # Fetch book
      book_query = select(Book).where(Book.id == book_id)
      result = await db.execute(book_query)
      book = result.scalar_one_or_none()

      if not book:
          raise HTTPException(
              status_code=status.HTTP_404_NOT_FOUND,
              detail=f"Book {book_id} not found"
          )

      # Count chunks
      chunk_count_query = select(func.count()).select_from(Chunk).where(Chunk.book_id == book_id)
      total_chunks = await db.scalar(chunk_count_query) or 0

      # Fetch recent logs (last 10 errors/warnings)
      from minerva.db.models.ingestion_log import IngestionLog

      logs_query = (
          select(IngestionLog)
          .where(
              IngestionLog.book_id == book_id,
              IngestionLog.log_level.in_(['WARNING', 'ERROR'])
          )
          .order_by(IngestionLog.created_at.desc())
          .limit(10)
      )
      logs_result = await db.execute(logs_query)
      logs = logs_result.scalars().all()

      # Build response
      return BookDetail(
          id=book.id,
          title=book.title,
          author=book.author,
          kindle_url=book.kindle_url,
          total_screenshots=book.total_screenshots,
          total_chunks=total_chunks,
          capture_date=book.capture_date,
          ingestion_status=book.ingestion_status,
          ingestion_error=book.ingestion_error,
          metadata=book.metadata,
          created_at=book.created_at,
          updated_at=book.updated_at,
          recent_logs=[
              IngestionLogItem(
                  log_level=log.log_level,
                  message=log.message,
                  created_at=log.created_at
              )
              for log in logs
          ]
      )
  ```

### Task 4: Create GET /api/v1/chunks/{chunk_id} endpoint (AC: 5, 6, 7)
- [ ] Create `minerva/api/routes/chunks.py` router
- [ ] Implement chunk details endpoint with context
  ```python
  from fastapi import APIRouter, Depends, HTTPException, status
  from sqlalchemy import select
  from sqlalchemy.ext.asyncio import AsyncSession
  from uuid import UUID

  from minerva.api.dependencies import get_db
  from minerva.api.schemas.books import ChunkDetail, ChunkContext, BookListItem
  from minerva.db.models.chunk import Chunk
  from minerva.db.models.book import Book

  router = APIRouter(prefix="/chunks", tags=["chunks"])

  @router.get(
      "/{chunk_id}",
      response_model=ChunkDetail,
      summary="Get chunk details",
      description="Retrieve chunk with surrounding context"
  )
  async def get_chunk(
      chunk_id: UUID,
      db: AsyncSession = Depends(get_db)
  ) -> ChunkDetail:
      # Fetch chunk with book
      chunk_query = (
          select(Chunk, Book)
          .join(Book, Chunk.book_id == Book.id)
          .where(Chunk.id == chunk_id)
      )
      result = await db.execute(chunk_query)
      row = result.one_or_none()

      if not row:
          raise HTTPException(
              status_code=status.HTTP_404_NOT_FOUND,
              detail=f"Chunk {chunk_id} not found"
          )

      chunk, book = row

      # Fetch previous chunk
      prev_query = (
          select(Chunk.chunk_text)
          .where(
              Chunk.book_id == chunk.book_id,
              Chunk.chunk_sequence == chunk.chunk_sequence - 1
          )
      )
      prev_result = await db.execute(prev_query)
      prev_text = prev_result.scalar_one_or_none()

      # Fetch next chunk
      next_query = (
          select(Chunk.chunk_text)
          .where(
              Chunk.book_id == chunk.book_id,
              Chunk.chunk_sequence == chunk.chunk_sequence + 1
          )
      )
      next_result = await db.execute(next_query)
      next_text = next_result.scalar_one_or_none()

      # Count total chunks for book
      chunk_count_query = select(func.count()).select_from(Chunk).where(Chunk.book_id == book.id)
      total_chunks = await db.scalar(chunk_count_query) or 0

      # Build response
      return ChunkDetail(
          chunk_id=chunk.id,
          chunk_text=chunk.chunk_text,
          chunk_sequence=chunk.chunk_sequence,
          chunk_token_count=chunk.chunk_token_count,
          book=BookListItem(
              id=book.id,
              title=book.title,
              author=book.author,
              total_screenshots=book.total_screenshots,
              total_chunks=total_chunks,
              capture_date=book.capture_date,
              ingestion_status=book.ingestion_status
          ),
          screenshot_ids=chunk.screenshot_ids,
          vision_model=chunk.vision_model,
          context=ChunkContext(
              previous_chunk=prev_text,
              next_chunk=next_text
          )
      )
  ```

### Task 5: Register routers in main.py (AC: 10)
- [ ] Add books and chunks routers to v1 API
  ```python
  from minerva.api.routes import books, chunks, search

  # In main.py
  api_v1_router.include_router(books.router)
  api_v1_router.include_router(chunks.router)
  api_v1_router.include_router(search.router)
  ```

### Task 6: Write integration tests (AC: 11)
- [ ] Create `tests/integration/test_books_chunks_endpoints.py`
- [ ] Test full workflow: list → book details → chunk details
  ```python
  @pytest.mark.asyncio
  async def test_full_retrieval_workflow(async_client, test_db_with_books):
      """Test complete workflow: list books → get book → get chunk."""

      # Step 1: List books
      response = await async_client.get("/api/v1/books")
      assert response.status_code == 200
      data = response.json()
      assert len(data["books"]) > 0
      assert "total_count" in data
      assert "has_more" in data

      book_id = data["books"][0]["id"]

      # Step 2: Get book details
      response = await async_client.get(f"/api/v1/books/{book_id}")
      assert response.status_code == 200
      book_data = response.json()
      assert book_data["id"] == book_id
      assert "total_chunks" in book_data
      assert "recent_logs" in book_data

      # Step 3: Get chunk (use test chunk ID)
      # Fetch a chunk ID from database first
      async with AsyncSessionLocal() as session:
          chunk_query = select(Chunk.id).where(Chunk.book_id == UUID(book_id)).limit(1)
          result = await session.execute(chunk_query)
          chunk_id = result.scalar_one()

      response = await async_client.get(f"/api/v1/chunks/{chunk_id}")
      assert response.status_code == 200
      chunk_data = response.json()
      assert chunk_data["chunk_id"] == str(chunk_id)
      assert "context" in chunk_data
      assert "book" in chunk_data
  ```
- [ ] Test pagination
  ```python
  async def test_books_pagination(async_client, test_db_with_many_books):
      """Test books list pagination works correctly."""

      # First page
      response = await async_client.get("/api/v1/books?limit=5&offset=0")
      assert response.status_code == 200
      data = response.json()
      assert len(data["books"]) == 5
      assert data["has_more"] is True

      # Second page
      response = await async_client.get("/api/v1/books?limit=5&offset=5")
      assert response.status_code == 200
      data = response.json()
      assert len(data["books"]) <= 5
  ```
- [ ] Test 404 errors
  ```python
  async def test_book_not_found(async_client):
      """Test 404 when book doesn't exist."""
      fake_id = "00000000-0000-0000-0000-000000000000"
      response = await async_client.get(f"/api/v1/books/{fake_id}")
      assert response.status_code == 404
      assert "not found" in response.json()["detail"].lower()

  async def test_chunk_not_found(async_client):
      """Test 404 when chunk doesn't exist."""
      fake_id = "00000000-0000-0000-0000-000000000000"
      response = await async_client.get(f"/api/v1/chunks/{fake_id}")
      assert response.status_code == 404
  ```
- [ ] Test status filter
  ```python
  async def test_books_status_filter(async_client, test_db_with_books):
      """Test filtering books by ingestion status."""
      response = await async_client.get("/api/v1/books?status=completed")
      assert response.status_code == 200
      data = response.json()

      # All returned books should have status "completed"
      for book in data["books"]:
          assert book["ingestion_status"] == "completed"
  ```

## Dev Notes

### Architecture Context

**Repository Pattern (Source: docs/architecture/coding-standards.md)**
- No raw `session.execute()` in route handlers
- Use BookRepository and ChunkRepository for database queries
- Repositories encapsulate SQL logic and provide clean interface
- Note: For this story, direct queries acceptable (repositories created in future refactor)

**Database Models (Source: docs/architecture/data-models.md)**
- Book: Main entity with title, author, ingestion_status, metadata
- Chunk: Text chunks with embedding, book_id, chunk_sequence
- IngestionLog: Audit trail for debugging (book_id, log_level, message)
- Relationships: Book → many Chunks, Book → many IngestionLogs

**Pagination Strategy (Source: docs/architecture/rest-api-specification.md)**
- Standard offset/limit pagination (not cursor-based)
- Default limit: 20 (reasonable for browsing)
- Max limit: 100 (prevent excessive data transfer)
- Response includes: total_count (total records), has_more (boolean flag)

**Context Window Pattern (Source: docs/stories/3.2.vector-search.md)**
- Reuse context retrieval pattern from vector search
- Fetch previous chunk: `chunk_sequence = current - 1`
- Fetch next chunk: `chunk_sequence = current + 1`
- Return null if no prev/next exists (first/last chunk)

### Previous Story Insights

**Story 3.1 (FastAPI Foundation):**
- Router pattern: APIRouter with prefix and tags
- Dependency injection: `db: AsyncSession = Depends(get_db)`
- Error handling: HTTPException with status codes and detail messages
- OpenAPI: Auto-generated docs from Pydantic schemas

**Story 3.3 (Search Endpoint):**
- Pydantic schemas for request/response validation
- Nested schemas: BookSummary embedded in SearchResultItem
- Schema examples in Config.schema_extra for OpenAPI
- Error responses: 404 for not found, 422 for validation errors

### Implementation Considerations

**Books List Optimization:**
- Single query with JOIN to count chunks (avoid N+1 queries)
- Use `func.count()` with GROUP BY for chunk counts
- ORDER BY created_at DESC for newest books first
- LIMIT/OFFSET at database level (efficient pagination)

**Book Details Complexity:**
- Multiple queries needed (book, chunk count, logs)
- Could optimize with single complex query + aggregates
- Recent logs: Only WARNING/ERROR (not INFO/DEBUG)
- Limit logs to 10 most recent (avoid large responses)

**Chunk Context Retrieval:**
- Sequential queries for prev/next (acceptable for single chunk)
- Alternative: Single query with window functions (more complex)
- Handle edge cases: First chunk (no prev), last chunk (no next)
- Return null for missing context (not empty string)

**404 vs 400 Error Codes:**
- 404: Resource doesn't exist (book_id, chunk_id not found)
- 400: Bad request (malformed UUID)
- 422: Validation error (Pydantic validation)
- Use appropriate codes for better API semantics

**Pagination Math:**
- has_more: `(offset + limit) < total_count`
- Examples:
  - Total 50, offset 0, limit 20 → has_more = True (20 < 50)
  - Total 50, offset 40, limit 20 → has_more = False (60 >= 50)
- Edge case: Empty results → has_more = False

### Dependencies

**New Files Created:**
- `minerva/api/schemas/books.py` (book/chunk schemas)
- `minerva/api/routes/books.py` (books endpoints)
- `minerva/api/routes/chunks.py` (chunks endpoints)
- `tests/integration/test_books_chunks_endpoints.py` (integration tests)

**Existing Files Used:**
- `minerva/api/dependencies.py` (get_db dependency)
- `minerva/db/models/book.py` (Book model)
- `minerva/db/models/chunk.py` (Chunk model)
- `minerva/db/models/ingestion_log.py` (IngestionLog model)
- `minerva/main.py` (register routers)

**External Dependencies (already in pyproject.toml):**
- `fastapi = "^0.104.0"`
- `sqlalchemy[asyncio] = "^2.0.0"`
- `pydantic = "^2.0.0"`

### Success Criteria

**Functional:**
- [x] GET /api/v1/books with pagination (limit, offset)
- [x] Filter books by ingestion_status
- [x] Response includes total_count and has_more
- [x] GET /api/v1/books/{book_id} returns full details
- [x] Book details include chunk count and recent logs
- [x] GET /api/v1/chunks/{chunk_id} returns chunk with context
- [x] Context includes prev/next chunk text
- [x] 404 errors for non-existent book_id/chunk_id

**Testing:**
- [x] Integration test: Full workflow (list → book → chunk)
- [x] Pagination test: Verify offset/limit/has_more
- [x] 404 tests: Book not found, chunk not found
- [x] Status filter test: Only matching status returned
- [x] Coverage: 80%+ for routes/books.py and routes/chunks.py

**Documentation:**
- [x] OpenAPI docs show all 3 endpoints
- [x] Schema examples for requests/responses
- [x] All response codes documented

### Next Steps (Story 3.5)

After Story 3.4 completion:
- **Story 3.5**: Export script for production database
  - CLI command: `minerva export --book-id <uuid>`
  - SQL export with INSERT statements
  - Excludes screenshot file_path (production has no screenshots)
  - Transaction wrapper for atomic import

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-06 | 1.0 | Initial story creation | Sarah (PO) |
| 2025-10-07 | 2.0 | Comprehensive redraft with architecture context | Bob (SM) |

## Dev Agent Record

### Agent Model Used
_To be filled by Dev Agent_

### Debug Log References
_To be filled by Dev Agent_

### Completion Notes
_To be filled by Dev Agent_

### File List
_To be filled by Dev Agent_

## QA Results
_To be filled by QA Agent_
